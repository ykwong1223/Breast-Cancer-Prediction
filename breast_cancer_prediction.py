# -*- coding: utf-8 -*-
"""WQD7003_GroupAssignment-Crazy Five (Breast Cancer Prediction)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DfNjAHDsLD_GAfadcY0fNFVwDeDybF7Q

# **WQD 7003 DATA ANALYTIC**

PREDICTIVE MODELING FOR BREAST CANCER DIAGNOSIS AND PROGNOSIS USING MACHINE
LEARNING APPROACHES

**GROUP MEMBER**:

CLEMENT TANG - S2190053

KOH RONG SOON - 22061463

LI YUJIE - 17103144

ONG YI KWONG - S2181260

THEN TSZE YEN - S2194020

# CRISP-DM

This project follows the CRISP-DM (Cross-Industry Standard Process for Data Mining) methodology, providing a structured framework for our analysis. CRISP-DM guides us through stages such as Business Understanding, Data Understanding, Data Preparation, Modeling, Evaluation, and Deployment. By adhering to this methodology, we ensure a comprehensive approach to analyzing breast cancer data.
"""

from google.colab import files
from IPython.display import Image

uploaded = files.upload()

Image('download (1).png',
    width = 525)

"""# Business Understanding

Breast cancer is a prevalent and serious disease affecting women worldwide. Early detection and accurate diagnosis are crucial for improving outcomes and reducing costs. Machine learning offers promising opportunities to analyze complex patient data, identify patterns, and provide personalized predictions. While previous studies have shown potential, further research is needed to enhance the accuracy and generalizability of machine learning models in breast cancer diagnosis and prognosis.

This breast cancer data analysis project benefits multiple stakeholders, including medical professionals, patients, and insurance providers. Medical professionals can enhance patient care and treatment decisions, patients can receive accurate diagnosis and personalized treatment plans, and insurance providers can assess risk and offer tailored insurance policies. By considering the specific needs of each stakeholder, we maximize the project's impact and value.


# Business Objective

1. Improve breast cancer detection by leveraging patient medical data to identify individuals at risk of breast cancer.
2. Enhance convenience for both patients and medical staff by streamlining the breast cancer detection process, making it more accessible and user-friendly.
3. Minimize resource waste and cost associated with breast cancer detection by implementing efficient and cost-effective methods.

# Data Mining Goals


1.   To develop and compare different machine learning models for breast cancer diagnosis and prognosis, such as decision trees, random forests, and support vector machines.
2.   To evaluate the performance of these models using metrics such as accuracy, precison, recall, and F1-Score.
3.   To identify the most important features that contribute to the accuracy of the models.

"""

from google.colab import files
from IPython.display import Image

uploaded = files.upload()

Image('breast cancer.jpeg',
    width = 525)

"""# Data Understanding"""

# Commented out IPython magic to ensure Python compatibility.
# Some imports - for style reasons, try and put in alphabetical order, unless there are subgroupings of imports
# that you want.
import matplotlib #we'll only use this to determine the matplotlib version number
import matplotlib.pyplot as plt  # the graphing library
import numpy as np # scientific computing library
import pandas as pd # the data structure and analysis library
from pandas import DataFrame, read_csv, Series # specific functions from pandas
import seaborn as sns # Makes graphs look pretty
import sys #we'll only use this to determine the python version number
import statistics

# Enable inline plotting.  The % is an iPython thing, and is not part of the Python language.
# In this case we're just telling the plotting library to draw things on
# the notebook, instead of on a separate window.
# %matplotlib inline

# Dataset collected from kaggle (Structured data) (Labelled Data)
breast_cancer = 'breast-cancer.csv'
df = pd.read_csv(breast_cancer)
df

"""## Summary of the dataset"""

df.head()

df.tail

df.shape

"""The Dataframe has 569 rows and 32 columns."""

df.columns

#Dataset information
df.info()

"""'id' is integer-type of data, 'diagnosis' is object-type of data and the rest of columns are float-type of data.

10 real-valued features of the cell nucleus:
1. Radius
2. Texture
3. Perimeter
4. Area
5. Smoothness
6. Compactness
7. Concavity
8. Concave points
9. Symmetry
10. Fractal dimension

These 10 real values are calculated in the form of mean, standard error, and "worst" which refers to the mean of the three largest values of the features. This results in giving output of 30 features.
"""

#Statistical description of dataset
df.describe()

df.describe().to_csv('statistical description.csv', index=False)

df.isna().sum()

"""There is no NA value in the dataset.

## Creating new dataframe
"""

columns_to_drop = ['id','radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se','compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se','fractal_dimension_se', 'radius_worst', 'texture_worst','perimeter_worst', 'area_worst', 'smoothness_worst','compactness_worst', 'concavity_worst', 'concave points_worst','symmetry_worst', 'fractal_dimension_worst']
new_df = df.drop(columns=columns_to_drop)

"""## Count of Malignant (M) and Benign (B)"""

#Graph for Count of Malignant (M) and Benign (B)
sns.countplot(data=new_df, x='diagnosis', palette='magma')

#Count of Malignant and Benign
diagnosis_count=new_df['diagnosis'].value_counts()
diagnosis_count

"""From the dataset, there are 357 Benign and 212 Malignant.

## Normality of each data
"""

new_df.columns

# Assuming you have a DataFrame named df with multiple columns
columns = ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']  # Specify the columns for which you want to create histograms

# Number of rows for subplots
num_rows = 4
# Calculate number of columns based on number of rows
num_cols = -(-len(columns) // num_rows)

# Create subplots with adjusted figsize
fig, axs = plt.subplots(num_rows, num_cols, figsize=(20, 16))

for i, column in enumerate(columns):
    row = i // num_cols
    col = i % num_cols

    sns.histplot(data=df, x=column, ax=axs[row, col], kde=True, color='indigo')  # Create histogram for each column
    axs[row, col].set_title(column)  # Set subplot title

# Remove empty subplots if there are any
if len(columns) < num_rows * num_cols:
    for i in range(len(columns), num_rows * num_cols):
        fig.delaxes(axs[i // num_cols, i % num_cols])

# Adjust spacing between subplots
plt.tight_layout()

# Display the plot
plt.show()

for column in columns:
    skewness = df[column].skew()
    kurtosis = df[column].kurt()
    print("Column: %s" % column)
    print("Skewness: %.2f" % skewness)
    print("Kurtosis: %.2f" % kurtosis)
    if -1 < skewness < 1:
      print("Distribution: Normally distributed")
    else:
      print("Distribution: Not normally distributed")

"""## Relationship of features using pairplot"""

# Create pairplot
sns.pairplot(new_df, hue='diagnosis', vars=['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean'], palette='magma')

"""## Diagonal Plot

In term of the diagonal plots, each plot corresponds to a specific feature such as 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', and 'fractal_dimension_mean'.

### Symmetrical Distribution:
For the shape of distribution, if the distribution is roughly symmetric and bell-shaped, it is normally distributed. This suggests that majority of the tumors in the dataset have similar values for that particular feature.

Features with symmetrical distribution for both diagnosis Benign and Malignant are 'radius_mean', 'texture_mean', 'perimeter_mean', 'smoothness_mean', 'concave points_mean', and 'symmetry_mean'. Benign has symmetrical distribution for 'area_mean' whereas Malignant has symmetrical distribution for 'compactness_mean', 'concavity_mean' and 'fractal_dimension_mean'.

### Skewed Distribution:
Positively Skewed (Right-skewed): In a positively skewed distribution, the tail of the distribution extends towards the right side. Features like 'compactness_mean', 'concavity_mean', and 'fractal_dimension_mean' exhibited positive skewness, suggesting that a smaller number of tumors have higher values for these features compared to the majority of tumors.

### Multimodal Distribution:
The presence of the multiple peaks in the diagonal plot indicates the existence of different groups or clusters within the malignant tumor data for 'radius_mean', 'perimeter_mean' and 'area_mean'. Each peak represents a distinct subgroup with its own characteristic values for the  corresponding variable.

## Scatter Plot
The off-diagonal scatter plots show the relationships between pairs of variables. In this case, we are interested in the scatter plots between the selected variables: 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', and 'fractal_dimension_mean'.

Perfect Positive Correlation: If the data points in a scatter plot form an upward sloping pattern from left to right, it indicates a positive correlation. This means that as one variable increases, the other variable tends to increase as well. For example, if the scatter plot of 'radius_mean against perimeter_mean', shows an upward trend. For instance, it suggests that larger values of radius are associated with larger perimeter values.

## Correlation Heatmap
"""

#Create Heatmap
plt.figure(figsize=(20, 10))
sns.heatmap(new_df.corr(), annot=True, cmap='magma')

plt.show()

"""##Boxplot"""

fig, ax = plt.subplots()

boxplot = ax.boxplot(new_df, flierprops={'marker': 'o', 'markersize': 5}, labels=new_df.keys())
ax.set_title('Box Plot with Circle Outliers')
ax.set_xlabel('Data')
plt.xticks(rotation=45)

plt.show()

"""# Data Preparation

As variable “diagnosis” datatype is in object, we replace it to value 1 and 0. Which 1 replacing B(benign) and 0 replacing M(malignant).
"""

#Replace diagnosis value to 0&1
new_df["diagnosis"].replace(["B","M"],[1,0],inplace=True)
print(new_df)

X=new_df.drop("diagnosis",axis=1)
y=new_df["diagnosis"]
new_df.describe()

"""# Modelling
Data is spilt to training and testing with ratio of 8:2.

In this project, there are **five** machile learning algorithms will be used.


*   Random Forest(RF)
*   Extreme Gradient Boost(XGB)
*   K-Nearest Neighbours(KNN)
*   Support Vector Machines(SVM)
*   Naive Bayes(NB)

Moreover, to improve performance of models, **grid search** is used in each model. The best models are selected.



"""

#import modules
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import GridSearchCV
import warnings
warnings.filterwarnings('ignore')

#performace Data Frame function
def performance(model):
  train_accuracy=accuracy_score(y_train, model.predict(X_train))
  test_accuracy=accuracy_score(y_test, model.predict(X_test))
  cv_scores=cross_val_score(model, X, y, cv=6)
  cv_score=np.mean(cv_scores)
  precision=precision_score(y_test, model.predict(X_test))
  recall=recall_score(y_test, model.predict(X_test))
  f1=f1_score(y_test, model.predict(X_test))
  performance_df=pd.DataFrame({"Model":str(model),"Model": [str(model)],
    "Train Accuracy": [train_accuracy],
    "Test Accuracy": [test_accuracy],
    "CV Score": [cv_score],
    "Precision": [precision],
    "Recall": [recall],
    "F1 Score": [f1]})
  return performance_df

#spilt dataset into training and test dataset into 8:2
X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=11)

#Random Forest Model
RF_model=RandomForestClassifier(random_state=11)
RF_model.fit(X_train,y_train)
print(RF_model.score(X_test,y_test))

#Random Forest Model with hypeparameter tuning
hyparam = {
    "n_estimators": np.arange(100, 300, 50),
    "max_depth": [None, np.arange(3, 10, 1)],
    "min_samples_split": np.arange(1, 10, 1),
    "min_samples_leaf": np.arange(1, 5, 1)
}
grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=11), param_grid=hyparam, cv=5)
grid_search.fit(X_train, y_train)
best_params = grid_search.best_params_
RF_model_tuned = grid_search.best_estimator_
print(best_params)
print(RF_model_tuned.score(X_test,y_test))

#XGBoost Model
XGB_model=xgb.XGBClassifier(random_state=11)
XGB_model.fit(X_train,y_train)
print(XGB_model.score(X_test,y_test))

#XGBoost Model with Hyperparameter Tuning
hyparam = {
    "learning_rate": np.arange(0.08, 0.09, 0.01),
    "n_estimators": np.arange(150, 200, 50),
    "max_depth": np.arange(5, 6, 1),
    "subsample": np.arange(0.6, 0.7, 0.1),
    "colsample_bytree": np.arange(0.7, 0.8, 0.1)
}
grid_search = GridSearchCV(estimator=xgb.XGBClassifier(random_state=11), param_grid=hyparam, cv=5)
grid_search.fit(X_train, y_train)
best_params = grid_search.best_params_
XGB_model_tuned = grid_search.best_estimator_
print(best_params)
print(XGB_model_tuned.score(X_test,y_test))

#KNN Model
KNN_model = KNeighborsClassifier()
KNN_model.fit(X_train,y_train)
print(KNN_model.score(X_test,y_test))

#KNN Model with hyperparameter tuning
hyparam = {"n_neighbors": np.arange(3, 10, 1), "weights": ["uniform", "distance"], "p": [1, 2]}
grid_search = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=hyparam, cv=5)
grid_search.fit(X_train, y_train)
best_params = grid_search.best_params_
KNN_model_tuned = grid_search.best_estimator_
print(best_params)
print(KNN_model_tuned.score(X_test,y_test))

#SVM Model
SVM_model = SVC(random_state=11)
SVM_model.fit(X_train,y_train)
print(SVM_model.score(X_test,y_test))

#SVM Model with hyperparameter tuning
hyparam = {'C': np.arange(5, 7, 1), "gamma": np.arange(0.1, 0.3, 0.1), "kernel": ["linear", "rbf"]}
grid_search = GridSearchCV(estimator=SVC(random_state=11), param_grid=hyparam, cv=5)
grid_search.fit(X_train, y_train)
best_params = grid_search.best_params_
SVM_model_tuned = grid_search.best_estimator_
print(best_params)
print(SVM_model_tuned.score(X_test,y_test))

#NB Model
NB_model = GaussianNB()
NB_model.fit(X_train,y_train)
NB_model.score(X_test,y_test)
print(NB_model.score(X_test,y_test))

#NB Model with hyperparameter tuning
hyparam = {"var_smoothing": np.arange(1e-10, 1e-9, 1e-10)}
grid_search = GridSearchCV(estimator=GaussianNB(), param_grid=hyparam, cv=5)
grid_search.fit(X_train, y_train)
best_params = grid_search.best_params_
NB_model_tuned = grid_search.best_estimator_
print(best_params)
print(NB_model_tuned.score(X_test,y_test))

"""#Evaluation
To evaluate these models, confusion matrix is plotted for every models, showing True Positive, False Negative, False Postive and True Negative. Besides, performance of each model is evaluated by calculating their accuracy, precision, recall and F1-Score.. In order to validate the performance of model, cross validation with 6 folds is also used. The performance of models with and without hyperparameter tuning are computed into DataFrame.
"""

cm1=confusion_matrix(y_test, RF_model.predict(X_test))
cm2=confusion_matrix(y_test, RF_model_tuned.predict(X_test))
cm3=confusion_matrix(y_test, XGB_model.predict(X_test))
cm4=confusion_matrix(y_test, XGB_model_tuned.predict(X_test))
cm5=confusion_matrix(y_test, KNN_model.predict(X_test))
cm6=confusion_matrix(y_test, KNN_model_tuned.predict(X_test))
cm7=confusion_matrix(y_test, SVM_model.predict(X_test))
cm8=confusion_matrix(y_test, SVM_model_tuned.predict(X_test))
cm9=confusion_matrix(y_test, NB_model.predict(X_test))
cm10=confusion_matrix(y_test, NB_model_tuned.predict(X_test))

title_plot = ["RF", "XGB", "KNN", "SVM", "NB", "Tuned RF", "Tuned XGB", "Tuned KNN", "Tuned SVM", "Tuned NB"]
all_cm = [cm1,cm3,cm5,cm7,cm9,cm2,cm4,cm6,cm8,cm10]

num_rows = 2
num_cols = 5

# Create a figure
fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 6))

axes = axes.flatten()

# Loop confusion matrices and plot
for i, cm in enumerate(all_cm):
    ax = axes[i]

    # Plot the confusion matrix
    ax.imshow(cm)

    # Set labels, title, and ticks
    ax.set_title(title_plot[i])
    ax.set_xlabel("Predicted")
    ax.set_ylabel("True")
    ax.set_xticks([0,1])
    ax.set_yticks([0,1])
    ax.xaxis.set_ticklabels([0,1])
    ax.yaxis.set_ticklabels([0,1])

    # Add text to the cells
    for i in range(len(cm)):
        for j in range(len(cm)):
            ax.text(i, j, str(cm[i, j]), color='black')

fig.tight_layout()


plt.show()

#Evaluate the performance of models
performance_RF=performance(RF_model)
performance_XGB=performance(XGB_model)
performance_KNN=performance(KNN_model)
performance_SVM=performance(SVM_model)
performance_NB=performance(NB_model)

performance_overall=pd.concat([performance_RF,performance_XGB,performance_KNN,performance_SVM,performance_NB])
performance_overall = performance_overall.sort_values(by='Test Accuracy',ascending=False)
performance_overall=pd.DataFrame(performance_overall).reset_index(drop=True)
print(performance_overall)

#Evaluate the performance of models with and with out hyperparameter tuned
performance_RF_tuned=performance(RF_model_tuned)
performance_XGB_tuned=performance(XGB_model_tuned)
performance_KNN_tuned=performance(KNN_model_tuned)
performance_SVM_tuned=performance(SVM_model_tuned)
performance_NB_tuned=performance(NB_model_tuned)

performance_overall=pd.concat([performance_RF,
                               performance_XGB,
                               performance_KNN,
                               performance_SVM,
                               performance_NB,
                               performance_RF_tuned,
                               performance_XGB_tuned,
                               performance_KNN_tuned,
                               performance_SVM_tuned,
                               performance_NB_tuned])

performance_overall = performance_overall.sort_values(by='Test Accuracy',ascending=False)
performance_overall=pd.DataFrame(performance_overall).reset_index(drop=True)
print(performance_overall)

#RF model's features ranking
feature_scores = pd.Series(RF_model.feature_importances_, index=X_train.columns).sort_values(ascending=False)
feature_scores
f, ax = plt.subplots(figsize=(12, 5))
ax = sns.barplot(x=feature_scores, y=feature_scores.index)
ax.set_title("RF Most Important Features")
ax.set_yticklabels(feature_scores.index)
ax.set_xlabel("Feature importance score")
ax.set_ylabel("Features")

#XGB model's features ranking
feature_scores = pd.Series(XGB_model.feature_importances_, index=X_train.columns).sort_values(ascending=False)
feature_scores
f, ax = plt.subplots(figsize=(12, 5))
ax = sns.barplot(x=feature_scores, y=feature_scores.index)
ax.set_title("XGB Most Important Features")
ax.set_yticklabels(feature_scores.index)
ax.set_xlabel("Feature importance score")
ax.set_ylabel("Features")

"""#Interpretation
Grid search for hyperparameter tuning has improved the performance of SVM and NB. KNN and RF's perfromance remains unchanged with XGB's performance has shown slightly decreased after hyperparameter tuning. Overall, **XGB without hypereparameter tuning** has shown the best performance among the 5 selected models with ***98.24% of accuracy*** and 0***.9730 F1-Score***. XGB is selected to be deployed. In addtion, the most important that contributes to the accuracy of the model is **concave_points_mean**.
In both RF and XGB, concave points_mean is the most important feature.

# Deployment

For the deployment part in this project, we had deploy our model by using **streamlit**. Streamlit is a free tools that allow us to deploy for our host our model into web application. We have choose the best performance model which is using **XGB** to deploy for deployment. The **joblib** library is use to serialize the machine learning model to disk and the machine learning model no need to rerun everytime for the web application. The main.py file is to write the web application interface. Lastly, the **main.py and XGB_model.joblib** files are push to the **GitHub** and hosting using the **StreamLit Cloud**.

Url to access: https://breastcancerprediction.streamlit.app/
"""

# !pip install -q streamlit
# !npm install localtunnel

import joblib
joblib.dump(XGB_model, 'XGB_model.joblib') # first run to save model to physical files

# Commented out IPython magic to ensure Python compatibility.
# %%writefile main.py
# 
# # Import all required modules
# import numpy as np
# import pandas as pd
# import joblib
# import streamlit as st
# import xgboost as xgb
# 
# # Load the model from joblib file
# model = joblib.load('XGB_model.joblib')
# 
# # Design for front end interface
# st.title('Breast Cancer Prediction')
# radius_mean = st.number_input('Radius mean:')
# texture_mean = st.number_input('Texture mean:')
# perimeter_mean = st.number_input('Perimeter mean:')
# area_mean = st.number_input('Area_mean:')
# smoothness_mean = st.number_input('Smoothness mean:')
# compactness_mean = st.number_input('Compactness mean:')
# concavity_mean = st.number_input('Concavity mean:')
# concavepoint_mean = st.number_input('Concavepoint mean:')
# symmetry_mean = st.number_input('Symmetry mean:')
# fractal_dimension_mean = st.number_input('Fractal dimension mean:')
# 
# cols = ['radius_mean','texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']
# 
# def predict():
#     row = np.array([radius_mean,texture_mean, perimeter_mean, area_mean, smoothness_mean, compactness_mean, concavity_mean, concavepoint_mean, symmetry_mean, fractal_dimension_mean])
#     x = pd.DataFrame([row], columns=cols)
#     prediction = model.predict(x)[0]
# 
#     if prediction == 0:
#         st.success('Low risk')
#     else:
#         st.error('High risk')
# 
# st.button('Predict', on_click=predict)

# !streamlit run main.py &/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com

"""# Conclusion
We have done this study following CRISP-DM Cycle. All the data ming goals are fulfill. Prediction models for breast cancer have been built. All the models are evaluated and the best performed model is XGB. The most imporatant feature found is concave_points_mean. XGB model has been deployed using streamit.

**GROUP MEMBER**:

CLEMENT TANG


*   Resonsible for data preparation


KOH RONG SOON


*   Responsible in deployment part with using streamlit and GitHub


LI YUJIE


*   Resonsible for bussiness understanding



ONG YI KWONG


*   Responsible for the modelling part



THEN TSZE YEN


*   Responsible for Data Understanding
"""